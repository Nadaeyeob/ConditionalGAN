{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acabc923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f46089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle_gan_drawing = np.load('C:\\\\Users\\\\sw991\\\\project\\\\230501_GAN\\\\image_data\\\\cycle_gan_drawing.npy')\n",
    "cycle_gan_img = np.load('image_data/cycle_gan_img.npy')\n",
    "\n",
    "# c_gan_1_drawing = np.load('C:\\\\Users\\\\sw991\\\\project\\\\230501_GAN\\\\image_data\\\\c_gan_1_drawing.npy')\n",
    "c_gan_1_img = np.load('image_data/c_gan_1_img.npy')\n",
    "\n",
    "# c_gan_3_drawing = np.load('C:\\\\Users\\\\sw991\\\\project\\\\230501_GAN\\\\image_data\\\\c_gan_3_drawing.npy')\n",
    "c_gan_3_img = np.load('image_data/c_gan_3_img.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba29de33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "all_digit = np.vstack((cycle_gan_img, c_gan_1_img))\n",
    "all_digit = np.vstack((all_digit, c_gan_3_img))\n",
    "del cycle_gan_img\n",
    "del c_gan_1_img\n",
    "del c_gan_3_img\n",
    "print(all_digit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cced9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dimension(data_set, img_size):\n",
    "    \n",
    "    for i in range(data_set.shape[0]):\n",
    "        img = data_set[i]\n",
    "        img = cv.resize(img, dsize=(img_size,img_size))\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        if i == 0:\n",
    "            new_data_set = img\n",
    "        else:\n",
    "            new_data_set = np.vstack((new_data_set, img))\n",
    "            \n",
    "    return new_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f062ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "new_digit = change_dimension(all_digit, 32)\n",
    "del all_digit\n",
    "print(new_digit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f1702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361ebd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0d08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1)\n"
     ]
    }
   ],
   "source": [
    "label_0 = np.expand_dims(np.zeros((300,)), axis = -1)\n",
    "label_1 = np.expand_dims(np.ones((300,)), axis = -1)\n",
    "label_3 = np.expand_dims(np.ones((300,)) * 3, axis = -1)\n",
    "\n",
    "all_label = np.vstack((label_0, label_1))\n",
    "all_label = np.vstack((all_label, label_3))\n",
    "print(all_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6b174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [new_digit, all_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4776883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d4dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from diffaug import DiffAugment\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0373a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_upsample(x, H, W):\n",
    "    # Data Input할 때 확인 필수\n",
    "    B, N, C = x.shape\n",
    "    assert N == H*W\n",
    "    x = tf.reshape(x, (-1, H, W, C))\n",
    "    # 굳이 depth_to_space 함수를 써야하는 이유는?\n",
    "    #합성곱 연산 사이의 활성화에서 데이터를 그대로 유지한 채로 크기를 변경시키는 때 유용\n",
    "    #예로, 풀링 대신 사용\n",
    "    x = tf.nn.depth_to_space(x, 2, data_format='NHWC')\n",
    "    B, H, W, C = x.shape\n",
    "    # Upsampling 후 재반환\n",
    "    x = tf.reshape(x, (-1, H*W, C))\n",
    "    return x, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bea1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_2nd_moment(x, axis=1, eps=1e-8):\n",
    "    return x *tf.math.rsqrt(tf.reduce_mean(tf.square(x),\n",
    "                                          axis = axis,\n",
    "                                           keepdims = True) + eps)\n",
    "\n",
    "def scaled_dot_product(q, k, v):\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    #dk는 key의 차원을 의미, attention value를 softmax(QKt / r(dk))로 명시\n",
    "    scaled_qk = tf.matmul(q, k, transpose_b =True) / tf.math.sqrt(dk)\n",
    "    \n",
    "    attn_weights = tf.nn.softmax(scaled_qk, axis = -1)\n",
    "    \n",
    "    # Padding Mask는 어디에 있는지 확인\n",
    "    output = tf.matmul(attn_weights, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47169ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형변환 > Attention 계산 > Head 결합\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    # model_dim이 어떻게 계산되서 들어가는지 확인 필요\n",
    "    # heads * depth = model_dim 인데, 왜 3개 값이 필요한지...\n",
    "    def __init__(self, model_dim, n_heads, initializer='glorot_uniform'):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        # Model_dimension과 Head 개수가 안맞으면 Fully 하게 결합 불가능\n",
    "        assert model_dim % n_heads == 0\n",
    "        self.depth = model_dim // n_heads\n",
    "        \n",
    "        # kernel initializer 에 대한 공부 필요\n",
    "        # Dense로 q,k,v 에 대한 가중치 행렬을 구함\n",
    "        self.wq = layers.Dense(model_dim, kernel_initializer=initializer)\n",
    "        self.wk = layers.Dense(model_dim, kernel_initializer=initializer)\n",
    "        self.wv = layers.Dense(model_dim, kernel_initializer=initializer)\n",
    "\n",
    "        self.dense = layers.Dense(model_dim, kernel_initializer=initializer)\n",
    "\n",
    "    def split_into_heads(self, x, batch_size):\n",
    "        # axis 1 외 다른 axis 값 고정\n",
    "        # self.depth는 model_dim을 heads 개수로 나눈 값\n",
    "        x = tf.reshape(x, (batch_size, -1, self.n_heads, self.depth))\n",
    "        # Data shape은 [batch_size, heads, ?, depth]\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    # Query, Key, Value\n",
    "    def call(self, q, k, v):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  \n",
    "        k = self.wk(k)  \n",
    "        v = self.wv(v)  \n",
    "\n",
    "        q = self.split_into_heads(q, batch_size)  \n",
    "        k = self.split_into_heads(k, batch_size)  \n",
    "        v = self.split_into_heads(v, batch_size)  \n",
    "\n",
    "        scaled_attention = scaled_dot_product(q, k, v)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) \n",
    "        original_size_attention = tf.reshape(scaled_attention,\n",
    "                                             (batch_size, -1, self.model_dim)) \n",
    "\n",
    "        output = self.dense(original_size_attention) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79ed1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_patches, model_dim, initializer='glorot_uniform'):\n",
    "        super().__init__()\n",
    "        self.n_patches = n_patches\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=n_patches, \n",
    "            output_dim=model_dim,\n",
    "            embeddings_initializer=initializer\n",
    "        )\n",
    "\n",
    "    def call(self, patches):\n",
    "        positions = tf.range(start=0, limit=self.n_patches, delta=1)\n",
    "        return patches + self.position_embedding(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8825c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 model_dim,\n",
    "                 n_heads=2,\n",
    "                 mlp_dim=512, \n",
    "                 rate=0.0,\n",
    "                 eps=1e-6,\n",
    "                 initializer='glorot_uniform'):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = MultiHeadAttention(model_dim, n_heads, initializer=initializer)\n",
    "        self.mlp = tf.keras.Sequential([\n",
    "            layers.Dense(mlp_dim,\n",
    "                         activation='gelu', \n",
    "                         kernel_initializer=initializer\n",
    "                        ), \n",
    "            layers.Dense(model_dim,\n",
    "                         kernel_initializer=initializer\n",
    "                        ),\n",
    "        ])\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=eps)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=eps)\n",
    "        self.drop1 = layers.Dropout(rate)\n",
    "        self.drop2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        #Multihead Attention 하기 전 Normalizaion\n",
    "        x_norm1 = self.norm1(inputs)\n",
    "        attn_output = self.attn(x_norm1, x_norm1, x_norm1)\n",
    "        attn_output = inputs + self.drop1(attn_output, training=training) \n",
    "        #wise-forward feed back layer 전 Normalization\n",
    "        x_norm2 = self.norm2(attn_output)\n",
    "        mlp_output = self.mlp(x_norm2)\n",
    "        \n",
    "        return attn_output + self.drop2(mlp_output, training=training)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60149eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.models.Model):\n",
    "    def __init__(self, model_dim=1024, \n",
    "                 noise_dim=256, \n",
    "                 depth=[5, 4, 2], \n",
    "                 heads=[4, 4, 4], \n",
    "                 mlp_dim=[4096, 1024, 256],\n",
    "                 initializer='glorot_uniform'):\n",
    "        super().__init__()\n",
    "        self.init = tf.keras.Sequential([\n",
    "            layers.Dense(8 * 8 * model_dim,\n",
    "                         use_bias=False, \n",
    "                         kernel_initializer=initializer),\n",
    "            layers.Reshape((8 * 8, model_dim))\n",
    "        ])     \n",
    "        \n",
    "        self.pos_emb_8 = PositionalEmbedding(64,\n",
    "                                             model_dim,\n",
    "                                             initializer=initializer)\n",
    "        self.block_8 = tf.keras.Sequential()\n",
    "        for _ in range(depth[0]):\n",
    "            self.block_8.add(TransformerBlock(model_dim,\n",
    "                                              heads[0],\n",
    "                                              mlp_dim[0], \n",
    "                                              initializer=initializer))\n",
    "         \n",
    "        self.pos_emb_16 = PositionalEmbedding(256,\n",
    "                                              model_dim // 4,\n",
    "                                              initializer=initializer)\n",
    "        self.block_16 = tf.keras.Sequential()\n",
    "        for _ in range(depth[1]):\n",
    "            self.block_16.add(TransformerBlock(model_dim // 4,\n",
    "                                               heads[1],\n",
    "                                               mlp_dim[1], \n",
    "                                               initializer=initializer))\n",
    "            \n",
    "        self.pos_emb_32 = PositionalEmbedding(1024,\n",
    "                                              model_dim // 16,\n",
    "                                              initializer=initializer)\n",
    "        self.block_32 = tf.keras.Sequential()\n",
    "        for _ in range(depth[2]):\n",
    "            self.block_32.add(TransformerBlock(model_dim // 16, \n",
    "                                               heads[2], \n",
    "                                               mlp_dim[2], \n",
    "                                               initializer=initializer))\n",
    "\n",
    "        self.ch_conv = layers.Conv2D(3, \n",
    "                                     kernel_size = 3,\n",
    "                                     strides = 1,\n",
    "                                     padding='same', \n",
    "                                     kernel_initializer=initializer)\n",
    "                       \n",
    "    def call(self, z):\n",
    "        B = z.shape[0]\n",
    "        x = normalize_2nd_moment(z)\n",
    "   \n",
    "        x = self.init(x)\n",
    "        x = self.pos_emb_8(x)\n",
    "        x = self.block_8(x)\n",
    "        x, H, W = pixel_upsample(x, 8, 8)\n",
    "        \n",
    "        x = self.pos_emb_16(x)\n",
    "        x = self.block_16(x)\n",
    "        x, H, W = pixel_upsample(x, H, W)\n",
    "        \n",
    "        x = self.pos_emb_32(x)\n",
    "        x = self.block_32(x)\n",
    "\n",
    "        x = tf.reshape(x, [B, H, W, -1])\n",
    "        #x.shape = (32,32,32,64)\n",
    "        return self.ch_conv(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "112001b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.models.Model):\n",
    "    def __init__(self,\n",
    "                 model_dim=[192, 192],\n",
    "                 depth=[3, 3],\n",
    "                 patch_size=2, \n",
    "                 heads=[4, 4, 4],\n",
    "                 mlp_dim=[768, 1536, 1536],\n",
    "                 img_size=32, \n",
    "                 policy='color,translation,cutout',\n",
    "                 initializer='glorot_uniform'):\n",
    "        super().__init__()\n",
    "        '''Encode image'''\n",
    "        patches_32 = (img_size // patch_size)**2\n",
    "        self.patch_32 = tf.keras.Sequential([\n",
    "            layers.Conv2D(model_dim[0],\n",
    "                          kernel_size=patch_size, \n",
    "                          strides=patch_size,\n",
    "                          padding='same',\n",
    "                          kernel_initializer=initializer)\n",
    "        ])\n",
    "        self.pos_emb_32 = PositionalEmbedding(n_patches=patches_32, \n",
    "                                              model_dim=model_dim[0],\n",
    "                                              initializer=initializer)\n",
    "        self.block_32 = tf.keras.Sequential()\n",
    "        for _ in range(depth[0]):\n",
    "            self.block_32.add(TransformerBlock(model_dim[0],\n",
    "                                               heads[0],\n",
    "                                               mlp_dim[0], \n",
    "                                               initializer=initializer))\n",
    "\n",
    "        patches_16 = ((img_size//2) // patch_size)**2\n",
    "        self.patch_16 = tf.keras.Sequential([\n",
    "            layers.Conv2D(model_dim[1],\n",
    "                          kernel_size=patch_size*2, \n",
    "                          strides=patch_size*2,\n",
    "                          padding='same',\n",
    "                          kernel_initializer=initializer)\n",
    "        ])\n",
    "        self.pos_emb_16 = PositionalEmbedding(n_patches=patches_16, \n",
    "                                              model_dim=model_dim[0] + model_dim[1])\n",
    "        self.block_16 = tf.keras.Sequential()\n",
    "        for _ in range(depth[1]):\n",
    "            self.block_16.add(TransformerBlock(model_dim[0] + model_dim[1], \n",
    "                                               heads[1], mlp_dim[1], initializer=initializer))\n",
    "        '''Last block'''\n",
    "        self.last_block=TransformerBlock(model_dim[0] + model_dim[1],\n",
    "                                         heads[2],\n",
    "                                         mlp_dim[2], \n",
    "                                         initializer=initializer)\n",
    "        self.norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "        '''Encode cls_token'''        \n",
    "        self.cls_dim = model_dim[0] + model_dim[1]\n",
    "        self.cls_token = self.add_weight(name='cls_token',\n",
    "                                         shape=(1, self.cls_dim),\n",
    "                                         initializer=initializer,\n",
    "                                         trainable=True)\n",
    "        '''Logits'''\n",
    "        self.logits = layers.Dense(1, kernel_initializer=initializer)\n",
    "        self.policy = policy\n",
    "\n",
    "    def call(self, img):\n",
    "        img = DiffAugment(img, self.policy)\n",
    "        x1 = self.patch_32(img)\n",
    "        B, H, W, C = x1.shape\n",
    "        x1 = tf.reshape(x1, [B, H * W, C]) \n",
    "        x1 = self.pos_emb_32(x1)\n",
    "        x1 = self.block_32(x1)\n",
    "        x1 = tf.reshape(x1, [B, H, W, -1]) \n",
    "        x1 = tf.nn.avg_pool2d(x1, [1,2,2,1], [1,2,2,1], 'SAME') \n",
    "        \n",
    "        x2 = self.patch_16(img)\n",
    "        B, H, W, C = x2.shape\n",
    "        x2 = tf.reshape(x2, [B, H * W, C]) \n",
    "        x1 = tf.reshape(x1, [B, H * W, -1]) \n",
    "        x = tf.concat([x1, x2], -1)\n",
    "        x = self.pos_emb_16(x)\n",
    "        x = self.block_16(x)\n",
    "\n",
    "        cls_tokens = tf.broadcast_to(self.cls_token, [B, 1, self.cls_dim])\n",
    "        x = tf.concat([cls_tokens, x], 1)\n",
    "        x = self.last_block(x)\n",
    "        x = self.norm(x)\n",
    "        return self.logits(x[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d22c63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:06:19.310390: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-25 16:06:19.310489: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93b5e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, z_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.z_dim = z_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean()\n",
    "        self.disc_loss_tracker = keras.metrics.Mean()\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "    \n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "    # Data 넣어줬을 때 Shape[0]이 곧 Batch_size로 써도 가능\n",
    "    @tf.function\n",
    "    def train_step(self, data, batch_size ):\n",
    "        raw_real_imgs = data[0]\n",
    "        raw_labels = data[1]\n",
    "        # data 항목에 One-hot encoding 진행하여 Input\n",
    "        # 소수점 등 집어넣기 위해 일단 OH encoding 미실시\n",
    "        \n",
    "        # idx = np.random.randint(0,raw_real_imgs.shape[0],batch_size)\n",
    "        \n",
    "        idx = list(np.random.randint(0,raw_real_imgs.shape[0],batch_size))\n",
    "        \n",
    "        # real_imgs = raw_real_imgs[idx]\n",
    "        real_imgs = tf.gather(raw_real_imgs, indices = idx)\n",
    "        real_imgs = tf.cast(real_imgs, tf.float32)\n",
    "        \n",
    "        # labels = raw_labels[idx]\n",
    "        labels = tf.gather(raw_labels, indices = idx)\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "                \n",
    "        # label > 256*256*1 size Layer로 만들어 concat 진행\n",
    "        img_labels = tf.repeat(labels, repeats = [image_size * image_size])\n",
    "        img_labels = tf.reshape(img_labels, shape=(-1, image_size,\n",
    "                                                  image_size, 1))\n",
    "        img_labels = tf.cast(img_labels, tf.float32)\n",
    "        \n",
    "        # discriminator 훈련 진행\n",
    "        z_dim_vector = tf.random.normal(shape = (batch_size, self.z_dim))\n",
    "        random_vector_labels = tf.concat([z_dim_vector, labels], axis = 1)\n",
    "        #random_vector_labels의 shape이 (Batch_size, channel)이고, Generator Input과 같아야함\n",
    "    \n",
    "        generated_imgs = self.generator(random_vector_labels)\n",
    "\n",
    "        fake_imgs_and_labels = tf.concat([generated_imgs, img_labels], axis = -1)\n",
    "        real_imgs_and_labels = tf.concat([real_imgs, img_labels], axis = -1)\n",
    "        \n",
    "        combined_imgs = tf.concat([fake_imgs_and_labels, real_imgs_and_labels], \n",
    "                                 axis = 0)\n",
    "        \n",
    "        combined_labels = tf.concat([tf.ones((batch_size,1)), tf.zeros((batch_size,1))],\n",
    "                          axis = 0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_imgs)\n",
    "            d_loss = self.loss_fn(combined_labels, predictions)\n",
    "            \n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, \n",
    "                                             self.discriminator.trainable_weights))\n",
    "        \n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        # generator 훈련 할 때 Discriminator를 훈련하지 않는 것인지 확인 필요\n",
    "        z_dim_vector = tf.random.normal(shape = (batch_size, self.z_dim))\n",
    "        random_vector_labels = tf.concat([z_dim_vector, labels], axis = 1)\n",
    "        misleading_labels = tf.zeros((batch_size,1))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, img_labels], axis = -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "            \n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        \n",
    "        self.discriminator.trainable = True\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b250196",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 256\n",
    "image_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e8c4ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_gan = ConditionalGAN(discriminator=discriminator, \n",
    "                          generator=generator, \n",
    "                          z_dim=z_dim)\n",
    "cond_gan.compile(d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "                 g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "                 loss_fn=keras.losses.BinaryCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54239cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, epoch, z_dim):\n",
    "    test_labels = np.array([[0],[1],[2],[3]])\n",
    "    z_dim_vector = tf.random.normal(shape = (4, z_dim))\n",
    "    random_vector_labels = tf.concat([z_dim_vector, test_labels], axis = 1)\n",
    "\n",
    "    prediction = model(random_vector_labels)\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    title = ['0', '1', '2', '3']\n",
    "\n",
    "    for i in range(test_labels.shape[0]):\n",
    "        \n",
    "        plt.subplot(1, test_labels.shape[0], i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(prediction[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.savefig('./image/Conditional_GAN_Image %d.png' %(epoch+1))\n",
    "    # Plt.show() 전에 저장 필요\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bbfe4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000000\n",
    "batch_size =32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02181d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:06:29.677559: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-25 16:06:29.683960: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for epoch 1 is 148.64892268180847 sec\n",
      "\n",
      "Time taken for epoch 2 is 125.42287611961365 sec\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mcond_gan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m     generate_images(generator, epoch, z_dim)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gantest/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gantest/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gantest/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gantest/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gantest/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gantest/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gantest/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    iterations = int(all_data[0].shape[0] / batch_size)\n",
    "    start = time.time()\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        cond_gan.train_step(all_data, batch_size)\n",
    "        \n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        generate_images(generator, epoch, z_dim)\n",
    "        cond_gan.save_weights('./checkpoints/my_checkpoint')\n",
    "        \n",
    "    if (epoch + 1) % 250 == 0:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                      time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5f8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b75787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c09d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
